services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: demo
      POSTGRES_USER: demouser
      POSTGRES_PASSWORD: demopass123
    volumes:
      - ./pg-init:/docker-entrypoint-initdb.d:ro
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - training-network

  ollama:
    image: ollama/ollama:latest
    environment:
      OLLAMA_KEEP_ALIVE: "24h"
    volumes:
      - ollama-models:/root/.ollama
    ports:
      - "11434:11434"
    # Start ollama serve in background, wait for it to be ready, pull the model, then keep serve running
    command: >
      bash -c "
      ollama serve &
      OLLAMA_PID=$!
      echo 'Waiting for Ollama to be ready...'
      for i in {1..30}; do
        if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
          echo 'Ollama is ready!'
          break
        fi
        sleep 1
      done
      echo 'Pulling llama3.2:1b model...'
      ollama pull llama3.2:1b || echo 'Model pull failed or already exists'
      wait $OLLAMA_PID
      "
    networks:
      - training-network

  client:
    image: node:20-slim
    stdin_open: true
    tty: true
    command: >
      bash -c "
      if [ ! -f /root/.setup-complete ]; then
        apt-get update &&
        apt-get install -y git curl jq vim &&
        npm install -g npm@10 &&
        npm install -g @modelcontextprotocol/server-filesystem &&
        npm install -g @mzxrai/mcp-webresearch &&
        npm install -g pg-mcp-server &&
        touch /root/.setup-complete
      fi &&
      exec bash
      "
    networks:
      - training-network

volumes:
  pgdata: {}
  ollama-models: {}

networks:
  training-network:
    driver: bridge

